{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T00:32:20.883270Z",
     "start_time": "2024-04-11T00:32:20.864469Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] The specified procedure could not be found'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict, defaultdict\n",
    "from typing import Dict\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a51bb6bb40fe60d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T00:32:20.895483Z",
     "start_time": "2024-04-11T00:32:20.883270Z"
    }
   },
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, stride=1, padding=2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.fc1 = nn.Linear(32 * 8 * 8, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))  # 3*32*32 -> 16*32*32\n",
    "        x = torch.max_pool2d(x, 2)  # 16*32*32 -> 16*16*16\n",
    "        x = torch.relu(self.conv2(x))  # 16*16*16 -> 32*16*16\n",
    "        x = torch.max_pool2d(x, 2)  # 32*16*16 -> 32*8*8\n",
    "        x = torch.flatten(x, start_dim=1, end_dim=-1)  # 32*8*8 -> 2048\n",
    "        x = torch.relu(self.fc1(x))  # 2048 -> 128\n",
    "        x = self.fc2(x)  # 128 -> 10\n",
    "        return x\n",
    "\n",
    "\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.base = nn.Sequential(\n",
    "            OrderedDict(\n",
    "                conv1=nn.Conv2d(3, 6, kernel_size=5, stride=1, padding=0),  # 3*32*32 -> 6*28*28\n",
    "                activation1=nn.ReLU(),\n",
    "                pool1=nn.AvgPool2d(2),  # 6*28*28 -> 6*14*14\n",
    "                conv2=nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0),  # 6*14*14 -> 16*10*10\n",
    "                activation2=nn.ReLU(),\n",
    "                pool2=nn.AvgPool2d(2),  # 16*10*10 -> 16*5*5\n",
    "                flatten=nn.Flatten(start_dim=1),  # 16*5*5 -> 400\n",
    "                fc1=nn.Linear(400, 120),  # 400 -> 120\n",
    "                activation3=nn.ReLU(),\n",
    "                fc2=nn.Linear(120, 84),  # 120 -> 84\n",
    "                activation4=nn.ReLU(),\n",
    "                fc3=nn.Linear(84, 10),  # 84 -> 10\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.base(x)\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        pretrained_weights = models.ResNet50_Weights.DEFAULT\n",
    "        resnet: models.ResNet = models.resnet50(weights=pretrained_weights)\n",
    "        self.base = resnet\n",
    "        self.classifier = nn.Linear(self.base.fc.in_features, 10)\n",
    "        self.base.fc = nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.classifier(self.base(x))\n",
    "\n",
    "\n",
    "class MobileNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        pretrained_weights = models.MobileNet_V3_Small_Weights.DEFAULT\n",
    "        mobilenet: models.MobileNetV3 = models.mobilenet_v3_small(weights=pretrained_weights)\n",
    "        self.base = mobilenet\n",
    "        self.classifier = nn.Linear(self.base.classifier[-1].in_features, 10)\n",
    "        self.base.classifier[-1] = nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.classifier(self.base(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1515c0943f408fb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T00:32:20.901027Z",
     "start_time": "2024-04-11T00:32:20.895483Z"
    }
   },
   "outputs": [],
   "source": [
    "_args = defaultdict(\n",
    "    model='simple',\n",
    "    dataset='cifar10',\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    lr=0.01,\n",
    ")\n",
    "\n",
    "model_dict = {\n",
    "    'simple': SimpleNet,\n",
    "    'lenet5': LeNet5,\n",
    "    'resnet50': ResNet,\n",
    "    'mobilenet': MobileNet,\n",
    "}\n",
    "dataset_dict = {\n",
    "    'cifar10': {\n",
    "        'loader': datasets.CIFAR10,\n",
    "        'mean': (0.4914, 0.4822, 0.4465),\n",
    "        'std': (0.247, 0.243, 0.261),\n",
    "    },\n",
    "    'mnist': {\n",
    "        'loader': datasets.MNIST,\n",
    "        'mean': (0.1307,),\n",
    "        'std': (0.3081,),\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f0b1bce0d80a2e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T00:32:20.906811Z",
     "start_time": "2024-04-11T00:32:20.901027Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_model(device=torch.device('cuda'),\n",
    "              _args=Dict,\n",
    "              ):\n",
    "    if _args['model'] in model_dict:\n",
    "        model = model_dict[_args['model']]().to(device)\n",
    "    else:\n",
    "        raise ValueError(f'model {_args[\"model\"]} is not supported')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_data(_args=Dict,\n",
    "             is_train=True,\n",
    "             ):\n",
    "    if _args['dataset'] in dataset_dict.keys():\n",
    "        temp_data = dataset_dict[_args['dataset']]\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(temp_data['mean'], temp_data['std']),\n",
    "        ])\n",
    "        dataset = temp_data['loader'](str(Path().parent / 'data'),\n",
    "                                      train=is_train, download=True, transform=transform)\n",
    "    else:\n",
    "        raise ValueError(f'dataset {_args[\"dataset\"]} is not supported')\n",
    "\n",
    "    data_loader = DataLoader(dataset, batch_size=_args['batch_size'], shuffle=True, num_workers=4)\n",
    "\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ede8f55c3df8a2eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T00:32:20.913405Z",
     "start_time": "2024-04-11T00:32:20.906811Z"
    }
   },
   "outputs": [],
   "source": [
    "def run(model,\n",
    "        dataloader,\n",
    "        loss_fn,\n",
    "        optimizer=None,\n",
    "        is_train=True,\n",
    "        device=torch.device('cuda'),\n",
    "        ):\n",
    "    total_loss, correct = 0.0, 0\n",
    "    data_len = len(dataloader.dataset)\n",
    "    model.train() if is_train else model.eval()\n",
    "\n",
    "    with torch.set_grad_enabled(is_train):\n",
    "        for data, target in dataloader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            loss = loss_fn(output, target)\n",
    "\n",
    "            if is_train:\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # 확률이 가장 높은 class를 예측값으로 선택\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    avg_loss = total_loss / data_len\n",
    "    accuracy = 100. * correct / data_len\n",
    "\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86120de2",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'get_num_thread'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_thread\u001b[49m()\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\lib\\site-packages\\torch\\__init__.py:1833\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m   1830\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mimportlib\u001b[39;00m\n\u001b[0;32m   1831\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m-> 1833\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch' has no attribute 'get_num_thread'"
     ]
    }
   ],
   "source": [
    "torch.get_num_threads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8fd20c096766aa9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T00:36:26.336731Z",
     "start_time": "2024-04-11T00:33:21.291607Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac169108fa504241b766cbf2674cfd1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/10 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: Loss: 0.05, Acc: 38.47%\n",
      "Epoch 2/10: Loss: 0.04, Acc: 52.26%\n",
      "Epoch 3/10: Loss: 0.04, Acc: 58.35%\n",
      "Epoch 4/10: Loss: 0.03, Acc: 63.02%\n",
      "Epoch 5/10: Loss: 0.03, Acc: 66.76%\n",
      "Epoch 6/10: Loss: 0.03, Acc: 69.71%\n",
      "Epoch 7/10: Loss: 0.02, Acc: 72.47%\n",
      "Epoch 8/10: Loss: 0.02, Acc: 74.60%\n",
      "Epoch 9/10: Loss: 0.02, Acc: 76.58%\n",
      "Epoch 10/10: Loss: 0.02, Acc: 78.54%\n",
      "Files already downloaded and verified\n",
      "Test Loss: 0.03, Test Acc: 70.24%\n"
     ]
    }
   ],
   "source": [
    "# Environments configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# model selection\n",
    "model = get_model(device, _args)\n",
    "# loss function\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "# optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=_args['lr'])\n",
    "\n",
    "# Model training\n",
    "train_loader = get_data(_args, is_train=True)\n",
    "for epoch in tqdm(range(_args['epochs']), total=_args['epochs'], unit='epoch', desc='Training'):\n",
    "    train_loss, train_acc = run(model, train_loader, loss_fn, optimizer, device=device, is_train=True)\n",
    "    tqdm.write(f'Epoch {epoch + 1}/{_args[\"epochs\"]}: Loss: {train_loss:.2f}, Acc: {train_acc:.2f}%')\n",
    "\n",
    "# Model test\n",
    "test_loader = get_data(_args, is_train=False)\n",
    "test_loss, test_acc = run(model, test_loader, loss_fn, device=device, is_train=False)\n",
    "print(f'Test Loss: {test_loss:.2f}, Test Acc: {test_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932d006d65fda271",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
